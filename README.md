# Fynd AI Intern â€“ Take Home Assessment ğŸš€

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![Flask](https://img.shields.io/badge/Flask-2.0%2B-green.svg)](https://flask.palletsprojects.com/)
[![Gemini](https://img.shields.io/badge/Gemini-2.5_Flash-orange.svg)](https://ai.google.dev/gemini-api)

This repository contains my complete solution for the **Fynd AI Intern Take Home Assessment**, covering both required tasks. Both tasks leverage LLMs (Gemini API â€“ free tier) and emphasize real-world AI system design, evaluation, and deployment.

## ğŸ“‹ Table of Contents
- [Tech Stack](#tech-stack)
- [Task 1 â€“ Rating Prediction via Prompting](#task-1--rating-prediction-via-prompting)
- [Task 2 â€“ Two-Dashboard AI Feedback System](#task-2--two-dashboard-ai-feedback-system)
- [How to Run Locally](#how-to-run-locally)
- [Deployment](#deployment)
- [Design Highlights](#design-highlights)
- [Conclusion](#conclusion)
- [Author](#author)
- [Contributing](#contributing)
- [License](#license)

## Tech Stack ğŸ› ï¸
| Category       | Technologies                          |
|----------------|---------------------------------------|
| **Language**   | Python                                |
| **LLM**        | Gemini 2.5 Flash (Free Tier)          |
| **Backend**    | Flask                                 |
| **Frontend**   | HTML, CSS, Bootstrap 5                |
| **Database**   | SQLite                                |
| **Notebook**   | Jupyter Notebook                      |
| **Deployment** | Render / HuggingFace Spaces / Vercel (as applicable) |

## Task 1 â€“ Rating Prediction via Prompting ğŸ“Š

### Objective
Predict Yelp review star ratings (1â€“5 stars) using prompt-based LLM classification, and return structured JSON output.

### Output Format
The LLM outputs predictions in structured JSON:
```json
{
  "predicted_stars": 4,
  "explanation": "Brief reasoning for the assigned rating."
}
Dataset

Source: Yelp Reviews Dataset (Kaggle)
File Used: yelp.csv
Rows Sampled: ~200 reviews (for evaluation efficiency)

Prompting Approaches
Three different prompting strategies were implemented:

Prompt v1 â€“ Basic Classification
Simple instruction to classify review into stars.
Minimal constraints.
Prompt v2 â€“ Guided Prompt
Explicit guidance on sentiment and rating mapping.
Improved consistency.
Prompt v3 â€“ Rubric-Based Prompt
Clear star-level rubric (1â€“5).
Enforced JSON-only response.

Evaluation Metrics
Each prompt was evaluated on:

Accuracy: Actual stars vs predicted stars
JSON Validity Rate: Correctly formatted JSON responses
Reliability: Consistency across similar reviews

Findings





























Prompt VersionAccuracyJSON ValidityConsistencyv1 BasicLowâ€“MediumMediumLowv2 GuidedMediumHighMediumv3 RubricHighVery HighHigh
âœ… Structured prompts with explicit rubrics significantly improved output quality.
Notebook Location
texttask1/
â””â”€â”€ rating_prediction_prompting.ipynb
Task 2 â€“ Two-Dashboard AI Feedback System ğŸ–¥ï¸
Objective
Build a web-based system with:

User Dashboard: Submit reviews & get AI replies
Admin Dashboard: View all feedback with AI insights

System Architecture
textUser â†’ Flask App â†’ Gemini LLM
               â†“
            SQLite DB
               â†“
         Admin Dashboard
Both dashboards share the same data source.
User Dashboard (Public-Facing) ğŸ‘¤
Users can:

Select star rating
Write a review
Submit feedback

On submission:

AI-generated reply is shown instantly
Feedback is stored in the database

Admin Dashboard (Internal-Facing) âš™ï¸
Displays:

Star rating
User review
AI-generated summary
AI-suggested recommended actions

Additional UX enhancements:

Styled AI action cards
Star visualization
Responsive table layout
Optional CSV/Excel export

LLM Usage in Task 2 ğŸ¤–
LLM is used for:

âœ… User-facing response generation
âœ… Review summarization
âœ… Recommended next actions

Data Storage

SQLite database
Single shared DB for both dashboards
Zero external DB setup required

How to Run Locally ğŸ 

Clone the repository:textgit clone https://github.com/yourusername/fynd-ai-intern-assessment.git
cd fynd-ai-intern-assessment
Install dependencies:textpip install -r requirements.txt
Set environment variables:textexport GEMINI_API_KEY="your_api_key_here"
Run the application:textpython app.py
Open in browser:
User Dashboard: http://127.0.0.1:5000
Admin Dashboard: http://127.0.0.1:5000/admin


Deployment ğŸš€
Both dashboards are deployed and accessible via public URLs.
(Links provided in final submission)
Design Highlights ğŸ¨

Minimalistic and responsive UI
Graceful handling of LLM rate limits
Clean separation of user and admin functionality
Real-world feedback workflow simulation

Conclusion ğŸ“
This project demonstrates:

Prompt engineering experimentation and evaluation
Practical LLM integration in a production-like system
Full-stack deployment of AI-powered applications

The solution satisfies all requirements of the Fynd AI Intern Take Home Assessment.
Author ğŸ‘¨â€ğŸ’»
Ajinkya
B.Tech Computer Science
AI & Data Science Enthusiast ğŸš€
LinkedIn | Portfolio | Email
Contributing ğŸ¤
Contributions welcome! Please open an issue or PR for bugs, features, or improvements. Follow the code of conduct.
License ğŸ“„
This project is licensed under the MIT License - see the LICENSE file for details.
